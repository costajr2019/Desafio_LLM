{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIgqlXXelNHJG968xiUjIQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/costajr2019/Desafio_LLM/blob/main/desafio_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Desafio da Imersão IA\n",
        "\n",
        "[Imersão Inteligência Artificial 2ª - Desafio da Aula 04](https://cursos.alura.com.br/imersoes/aulas/aula-4-criando-seu-proprio-chatbot-com-a-gemini-api-no-google-colab-c131)\n",
        "\n",
        "## Descrição Aprimorada dos Objetivos deste Projeto Colab\n",
        "\n",
        "### Objetivo Geral\n",
        "\n",
        "Desenvolver um script Python que utilize o LLM (Large Language Model) da Google para realizar análises e fornecer feedback detalhado sobre códigos Python escritos por alunos.\n",
        "\n",
        "### Funcionalidades Específicas\n",
        "\n",
        "* **Análise de Código:** O script deverá analisar códigos Python (postados por alunos) localizados em uma pasta chamada \"respostas\". Cada código estará em um arquivo individual.\n",
        "* **Comparação com Gabarito:** O código do aluno será comparado com um código gabarito presente em um arquivo chamado \"gabarito.txt\".\n",
        "* **Feedback Automatizado:** Através do LLM da Google, o script irá gerar feedback detalhado sobre o código do aluno, identificando erros, sugerindo melhorias e fornecendo orientações para otimização.\n",
        "* **Armazenamento de Feedback:** O feedback gerado pelo LLM será armazenado nos respectivos arquivos dos alunos na pasta \"feedback\". O feedback será inserido como comentários no código, facilitando a consulta e compreensão por parte dos alunos.\n",
        "\n",
        "### Benefícios do Projeto\n",
        "\n",
        "* **Aprimoramento da Aprendizagem:** O feedback automatizado e personalizado auxiliará os alunos na identificação de erros e na compreensão de conceitos importantes em Python, promovendo um aprendizado mais eficaz e direcionado.\n",
        "* **Eficiência na Correção:** A automatização da análise e do feedback otimiza o tempo de trabalho dos professores, liberando-os para se concentrarem em tarefas mais complexas e na interação individualizada com os alunos.\n",
        "* **Escalabilidade:** O script pode ser facilmente adaptado para analisar um grande número de códigos, tornando-o ideal para turmas com muitos alunos ou para cursos online com alto volume de inscrições.\n",
        "\n",
        "### Aplicações\n",
        "\n",
        "* **Cursos de Programação:** O projeto pode ser utilizado em cursos de programação para auxiliar na avaliação de tarefas e na entrega de feedback aos alunos.\n",
        "* **Treinamentos Online:** O script pode ser integrado a plataformas de treinamento online para fornecer feedback em tempo real aos participantes durante a realização de exercícios práticos.\n",
        "* **Competições de Programação:** O projeto pode ser utilizado como ferramenta de avaliação em competições de programação, automatizando a análise e a classificação dos códigos submetidos pelos participantes.\n",
        "\n",
        "### Observações\n",
        "\n",
        "* O script Python deverá ser implementado de forma clara, concisa e bem documentada, facilitando sua compreensão e utilização por outros usuários.\n",
        "* O LLM da Google pode ser acessado através da API oficial do Google AI.\n",
        "* O script poderá ser adaptado para analisar outros tipos de arquivos, como arquivos de texto com outros formatos de linguagem de programação.\n",
        "\n",
        "### Conclusão\n",
        "\n",
        "Este projeto Colab apresenta um grande potencial para aprimorar o processo de aprendizado e avaliação em cursos de programação, otimizando o tempo de trabalho dos professores e promovendo uma experiência de aprendizado mais personalizada e eficaz para os alunos.\n",
        "\n",
        "##Dados\n",
        "\n",
        "| Arquivo | Conteúdo | Local de Armazenamento |\n",
        "| ---| --- | --- |\n",
        "| gabarito.txt | Script que produz a solução para o problema proposto.| Pasta Raíz |\n",
        "| prompt.txt | Prompt que descreve o conteúdo e a forma que o LLM deve apresentar sua análise. | Pasta Raíz\n",
        "| resposta_alunoN.txt | Script do N-ésimo aluno a ser avaliado pelo LLM | Pasta \"respostas\"\n",
        "\n",
        "##Saída\n",
        "| Arquivo | Conteúdo | Local de Armazenamento |\n",
        "|---|---| --- |\n",
        "| feedback_resposta_alunoN.txt | Feedback do LLM sobre o Script do N-ésimo aluno | Pasta \"feedback\"\n",
        "\n",
        "##Metodologia\n",
        "1. Para cada aluno, concatenar os conteúdos dos arquivos \"prompt.txt\", \"gabarito.txt\", e \"resposta_alunoN.txt\" para formar uma string contendo o prompt completo.\n",
        "2. Obter da LLM a avaliação do script Python de cada aluno a partir do respectivo prompt completo.\n",
        "3. Gravar as avaliações em arquivos separados na pasta \"feedback\"\n"
      ],
      "metadata": {
        "id": "YormlGbAHwWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função `concatenar_strings` tem como objetivo concatenar o conteúdo de três strings em uma única string formatada. Essa string final conterá o prompt do exercício, a resposta do aluno, e o gabarito, separados por marcadores visuais.\n",
        "\n",
        "### Argumentos\n",
        "\n",
        "* `conteudo_prompt`: Uma string contendo o prompt do exercício.\n",
        "* `conteudo_resposta`: Uma string contendo a resposta do aluno ao exercício.\n",
        "* `conteudo_gabarito`: Uma string contendo o gabarito do exercício.\n",
        "\n",
        "### Retorno\n",
        "\n",
        "A função retorna uma única string contendo a concatenação formatada do prompt, resposta e gabarito.\n"
      ],
      "metadata": {
        "id": "NwhfVtLor3JU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BrcPStNBHsUz"
      },
      "outputs": [],
      "source": [
        "def concatenar_strings(conteudo_prompt, conteudo_resposta, conteudo_gabarito):\n",
        "  \"\"\"\n",
        "  Função para concatenar o conteúdo de três strings em uma única string.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Cria a string separadora\n",
        "  separador = \"-\" * 50 + \"\\n\"\n",
        "\n",
        "  # Concatena os conteúdos dos arquivos\n",
        "  texto_concatenado = (\n",
        "      conteudo_prompt\n",
        "      + 2 * \"\\n\"\n",
        "      + \"**RESPOSTA DO ALUNO**\"\n",
        "      + \"\\n\"\n",
        "      + separador\n",
        "      + conteudo_resposta\n",
        "      + \"\\n\"\n",
        "      + \"\\n\"\n",
        "      + \"**GABARITO**\"\n",
        "      + \"\\n\"\n",
        "      + separador\n",
        "      + conteudo_gabarito\n",
        "  )\n",
        "\n",
        "  return texto_concatenado"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função `processar_respostas_alunos` tem como objetivo processar todas as respostas dos alunos em uma pasta especificada. Essa função lê os arquivos de prompt, resposta do aluno e gabarito, concatena seus conteúdos e armazena o resultado em um dicionário.\n",
        "\n",
        "### Argumentos\n",
        "\n",
        "* `pasta_respostas`: O caminho para a pasta que contém as respostas dos alunos.\n",
        "\n",
        "### Retorno\n",
        "\n",
        "A função retorna um dicionário onde as chaves são os nomes dos arquivos de resposta (sem a extensão `.txt`) e os valores são as strings concatenadas contendo as respostas, prompts e gabaritos.\n",
        "\n",
        "### Detalhes da Implementação\n",
        "\n",
        "**1. Importação do Módulo `os`:**\n",
        "\n",
        "A função inicia importando o módulo `os` da biblioteca padrão do Python. O módulo `os` fornece funções para trabalhar com o sistema operacional, como listar diretórios, criar e remover arquivos, etc.\n",
        "\n",
        "**2. Definição da Função `processar_respostas_alunos`:**\n",
        "\n",
        "A função `processar_respostas_alunos` é definida com um parâmetro obrigatório `pasta_respostas`. Esse parâmetro representa o caminho para a pasta que contém as respostas dos alunos.\n",
        "\n",
        "**3. Carregamento dos Conteúdos dos Arquivos:**\n",
        "\n",
        "Dentro da função, três arquivos são abertos e seus conteúdos lidos em variáveis:\n",
        "\n",
        "* `prompt.txt`: O conteúdo do arquivo `prompt.txt` é lido na variável `prompt`.\n",
        "* `gabarito.txt`: O conteúdo do arquivo `gabarito.txt` é lido na variável `gabarito`.\n",
        "* `resposta_aluno.txt`: Para cada arquivo na pasta de respostas, o conteúdo é lido na variável `resposta_aluno`.\n",
        "\n",
        "**4. Inicialização do Dicionário de Respostas Processadas:**\n",
        "\n",
        "Um dicionário vazio chamado `respostas_processadas` é criado para armazenar as respostas concatenadas.\n",
        "\n",
        "**5. Iteração pelos Arquivos na Pasta:**\n",
        "\n",
        "A função utiliza um loop `for` para iterar pelos arquivos na pasta `pasta_respostas`. Para cada arquivo:\n",
        "\n",
        "* **Verificação da Extensão do Arquivo:** A função verifica se a extensão do arquivo termina com `.txt`. Se sim, prossegue para o próximo passo.\n",
        "* **Separação do Nome do Arquivo e Extensão:** A função utiliza `os.path.splitext` para separar o nome do arquivo (sem extensão) e a extensão em variáveis `nome_arquivo` e `extensao`, respectivamente.\n",
        "* **Abertura do Arquivo de Resposta do Aluno:** A função utiliza `os.path.join` para concatenar o caminho da pasta e o nome do arquivo, criando o caminho completo do arquivo de resposta do aluno. Esse arquivo é aberto em modo de leitura (`'r'`) utilizando a instrução `with open`.\n",
        "* **Leitura do Conteúdo da Resposta do Aluno:** O conteúdo do arquivo de resposta do aluno é lido na variável `resposta_aluno`.\n",
        "* **Concatenação dos Conteúdos:** A função `concatenar_strings` (que deve ser definida separadamente) é chamada para concatenar o prompt, a resposta do aluno e o gabarito em uma única string.\n",
        "* **Armazenamento da Resposta Concatenada no Dicionário:** A string concatenada é armazenada no dicionário `respostas_processadas` utilizando o nome do arquivo (sem extensão) como chave.\n",
        "\n",
        "**6. Retorno do Dicionário de Respostas:**\n",
        "\n",
        "A função retorna o dicionário `respostas_processadas` contendo as respostas concatenadas para cada arquivo de resposta.\n"
      ],
      "metadata": {
        "id": "zcfQfM09tArT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def processar_respostas_alunos(pasta_respostas):\n",
        "  \"\"\"\n",
        "  Função para processar todas as respostas dos alunos em uma pasta.\n",
        "\n",
        "  Argumentos:\n",
        "    pasta_respostas: O caminho para a pasta que contém as respostas dos alunos.\n",
        "\n",
        "  Retorno:\n",
        "    Um dicionário onde as chaves são os nomes dos arquivos de resposta e os valores são as strings concatenadas contendo as respostas, prompts e gabaritos.\n",
        "  \"\"\"\n",
        "\n",
        "  # Carregar o conteúdo de prompt.txt, resposta_aluno.txt e gabarito.txt\n",
        "  with open(\"prompt.txt\") as prompt_file:\n",
        "    prompt = prompt_file.read()\n",
        "\n",
        "  with open(\"gabarito.txt\") as gabarito_file:\n",
        "    gabarito = gabarito_file.read()\n",
        "\n",
        "  respostas_processadas = {}\n",
        "\n",
        "  for arquivo in os.listdir(pasta_respostas):\n",
        "    if arquivo.endswith(\".txt\"):\n",
        "      nome_arquivo, extensao = os.path.splitext(arquivo)\n",
        "\n",
        "      with open(os.path.join(pasta_respostas, arquivo), 'r') as resposta_aluno_file:\n",
        "        resposta_aluno = resposta_aluno_file.read()\n",
        "\n",
        "      # Concatenar os conteúdos usando a função concatenar_arquivos\n",
        "      texto_concatenado = concatenar_strings(prompt, resposta_aluno, gabarito)\n",
        "\n",
        "      # Armazenar o texto concatenado no dicionário com o nome do arquivo como chave\n",
        "      respostas_processadas[nome_arquivo] = texto_concatenado\n",
        "\n",
        "  return respostas_processadas\n",
        "\n",
        "pasta_respostas = \"respostas\"\n",
        "prompts_preparados =  processar_respostas_alunos(pasta_respostas)\n"
      ],
      "metadata": {
        "id": "vjV1dvZfmNh0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Escrever o feedback de cada resposta da IA no correspondente arquivo na pasta feedback."
      ],
      "metadata": {
        "id": "X4x1rit_pIaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação do Pacote `google-generativeai`\n",
        "\n",
        "A instrução `!pip install -q -U google-generativeai` que você forneceu tem como objetivo instalar o pacote `google-generativeai` do Google Colab. Este pacote oferece acesso a modelos de linguagem e APIs de geração de texto avançados do Google AI.\n",
        "\n",
        "**Detalhes da Instalação:**\n",
        "\n",
        "* **`pip`:** O comando utiliza a ferramenta `pip` (Python Package Indexer) para gerenciar a instalação de pacotes Python.\n",
        "* **`install`:** Especifica a ação de instalação de um pacote.\n",
        "* **`-q`:** Avisa ao `pip` para suprimir a saída padrão, resultando em uma instalação silenciosa.\n",
        "* **`-U`:** Indica que a instalação deve atualizar o pacote para a versão mais recente disponível.\n",
        "* **`google-generativeai`:** Nome do pacote a ser instalado.\n"
      ],
      "metadata": {
        "id": "NoHvJjUFtPoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "JeeWPmXZpkuY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração do SDK Python para o Google Generative AI\n",
        "\n",
        "O código que você forneceu demonstra a configuração do SDK Python para o Google Generative AI. Vamos analisar cada linha para entender sua funcionalidade:\n",
        "\n",
        "**1. Importação do Módulo:**\n",
        "\n",
        "* `# Import the Python SDK` - (Comentário) Indica que o trecho a seguir é um comentário e não será executado pelo Python.\n",
        "* `import google.generativeai as genai` - Importa o módulo `google.generativeai` e atribui o alias `genai` para facilitar a referência posterior. Este módulo fornece acesso às APIs do Google Generative AI para geração de texto, tradução e outras funcionalidades.\n",
        "\n",
        "**2. Importação do Módulo `userdata`:**\n",
        "\n",
        "* `from google.colab import userdata` - Importa o módulo `userdata` do Google Colab. Este módulo fornece ferramentas para acessar e gerenciar dados privados associados ao seu notebook do Colab.\n",
        "\n",
        "**3. Recuperação da API Key:**\n",
        "\n",
        "* `api_key = userdata.get('SECRET_KEY')` - Recupera o valor da chave secreta `SECRET_KEY` armazenada no armazenamento seguro do Colab utilizando o módulo `userdata.get`. A API Key é uma credencial necessária para autenticar e autorizar o uso do Google Generative AI.\n",
        "\n",
        "**4. Configuração do SDK:**\n",
        "\n",
        "* `genai.configure(api_key = api_key)` - Configura o SDK do Google Generative AI utilizando a API Key recuperada anteriormente. Essa configuração permite que o SDK use a chave correta para autenticação nas chamadas de API.\n",
        "\n",
        "**Observações:**\n",
        "\n",
        "* É crucial armazenar a API Key com segurança. O Google Colab oferece armazenamento seguro de dados privados através do módulo `userdata`.\n",
        "* Substitua `'SECRET_KEY'` pelo nome real da chave secreta que você obteve do Google AI Platform.\n",
        "* Certifique-se de ter uma conexão ativa com a internet para que a configuração do SDK seja bem-sucedida.\n",
        "\n",
        "**Após a Configuração:**\n",
        "\n",
        "Uma vez configurado, você pode utilizar o módulo `genai` (que é o alias para `google.generativeai`) para acessar os modelos e funcionalidades do Google Generative AI.\n"
      ],
      "metadata": {
        "id": "5s6RNetDtRtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('SECRET_KEY')\n",
        "genai.configure(api_key = api_key)"
      ],
      "metadata": {
        "id": "VzP8aLPzpGsL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O dicionário `generation_config` que você forneceu define parâmetros para controlar a geração de texto com o Google Generative AI. Vamos analisar cada chave e valor para entender seus efeitos:\n",
        "\n",
        "**1. `candidate_count`:**\n",
        "\n",
        "* **Tipo:** Inteiro\n",
        "* **Descrição:** Define o número de candidatos de texto a serem gerados pelo modelo. Um valor maior pode resultar em mais opções, mas também aumenta o tempo de processamento.\n",
        "* **Valor padrão:** 1 (gera apenas um candidato)\n",
        "* **Exemplos:**\n",
        "    * `candidate_count = 2`: Gera dois candidatos de texto para cada prompt.\n",
        "    * `candidate_count = 5`: Gera cinco candidatos de texto para cada prompt.\n",
        "\n",
        "**2. `temperature`:**\n",
        "\n",
        "* **Tipo:** Número real\n",
        "* **Descrição:** Controla o nível de criatividade na geração de texto. Valores mais altos aumentam a probabilidade de gerar texto inesperado ou surpreendente, enquanto valores mais baixos favorecem a geração de texto mais previsível e semelhante ao texto de treinamento.\n",
        "* **Valor padrão:** 0.9\n",
        "* **Exemplos:**\n",
        "    * `temperature = 0.5`: Gera texto mais conservador e próximo ao texto de treinamento.\n",
        "    * `temperature = 1.5`: Gera texto mais criativo e original, com maior probabilidade de conter elementos inesperados.\n",
        "\n",
        "**3. `top_p` (opcional):**\n",
        "\n",
        "* **Tipo:** Número real\n",
        "* **Descrição:** Define a probabilidade cumulativa máxima para cada token durante a geração de texto. Um valor mais alto aumenta a probabilidade de gerar tokens mais comuns no idioma, enquanto um valor mais baixo aumenta a probabilidade de gerar tokens raros ou inesperados.\n",
        "* **Valor padrão:** Não definido (se não for especificado, o modelo usará um valor otimizado internamente)\n",
        "* **Exemplos:**\n",
        "    * `top_p = 0.9`: Prioriza tokens mais comuns, resultando em texto mais previsível.\n",
        "    * `top_p = 0.1`: Permite que tokens raros ou inesperados sejam gerados com mais frequência, resultando em texto mais criativo e original.\n",
        "\n",
        "**Observações:**\n",
        "\n",
        "* A escolha dos valores para `candidate_count`, `temperature` e `top_p` depende da sua necessidade específica e do tipo de texto que você deseja gerar. Experimente diferentes valores para encontrar a combinação que melhor se adapta aos seus objetivos.\n",
        "* Esses parâmetros podem afetar a qualidade e o tempo de processamento da geração de texto.\n",
        "* Consulte a documentação oficial do Google Generative AI para obter mais informações sobre os parâmetros de geração e como ajustá-los para obter os melhores resultados.\n"
      ],
      "metadata": {
        "id": "_pInBxIwtfKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\" : 1,\n",
        "    \"temperature\" : 0.9, # Nível de criatividade\n",
        "    #\"top_p\" : 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "jJdvKF5ap5Yj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração de Filtros de Segurança para o Google Generative AI\n",
        "\n",
        "O dicionário `safety_settings` que você forneceu define as configurações para os filtros de segurança do Google Generative AI. Esses filtros ajudam a mitigar a geração de texto prejudicial ou inadequado. Vamos analisar cada chave e valor para entender sua funcionalidade:\n",
        "\n",
        "**Chaves:**\n",
        "\n",
        "* **\"HARASSMENT\"**: Determina o nível de bloqueio para conteúdo que possa ser considerado assédio.\n",
        "* **\"HATE\"**: Determina o nível de bloqueio para conteúdo que possa ser considerado discurso de ódio.\n",
        "* **\"SEXUAL\"**: Determina o nível de bloqueio para conteúdo sexualmente explícito.\n",
        "* **\"DANGEROUS\"**: Determina o nível de bloqueio para conteúdo perigoso ou violento.\n",
        "\n",
        "**Valores:**\n",
        "\n",
        "* **\"BLOCK_NONE\"**: Desabilita o filtro de segurança para a respectiva categoria. O modelo poderá gerar conteúdo que se enquadre nessa categoria.\n",
        "* **\"BLOCK_SOME\"**: Ativa o filtro de segurança com bloqueio moderado. O modelo tentará evitar gerar conteúdo prejudicial, mas pode haver vazamentos ocasionais.\n",
        "* **\"BLOCK_MOST\"**: Ativa o filtro de segurança com bloqueio rigoroso. O modelo tentará evitar gerar a maioria do conteúdo prejudicial, mas é possível que alguns casos escapem.\n"
      ],
      "metadata": {
        "id": "TcycqhTXt5qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\" : \"BLOCK_NONE\",\n",
        "    \"HATE\" : \"BLOCK_NONE\",\n",
        "    \"SEXUAL\" : \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\" : \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "mq1s0y2fp8M9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação de um Modelo Generativo no Google Generative AI\n",
        "\n",
        "O código que você forneceu demonstra a criação de um modelo generativo utilizando a biblioteca `google.generativeai`. Vamos analisar cada parte para entender sua função:\n",
        "\n",
        "**1. Importação do Módulo (já pressupomos que ele foi importado):**\n",
        "\n",
        "* `from genai.models import GenerativeModel` (assumindo que a importação já foi realizada anteriormente).\n",
        "\n",
        "**2. Criação do Modelo:**\n",
        "\n",
        "* `model = genai.GenerativeModel(model_name= \"gemini-1.0-pro\", generation_config = generation_config, safety_settings = safety_settings)` - Esta linha cria uma instância da classe `GenerativeModel`.\n",
        "\n",
        "**Parâmetros:**\n",
        "\n",
        "* `model_name` (Obrigatório): Nome do modelo generativo que você deseja utilizar. No caso, `\"gemini-1.0-pro\"`. Consulte a documentação do Google Generative AI para obter uma lista de modelos disponíveis.\n",
        "* `generation_config` (opcional): Dicionário contendo parâmetros para controlar a geração de texto (já documentado anteriormente).\n",
        "* `safety_settings` (opcional): Dicionário contendo configurações para os filtros de segurança (já documentado anteriormente).\n",
        "\n",
        "**Observações:**\n",
        "\n",
        "* É necessário ter uma conexão ativa com a internet para criar o modelo.\n",
        "* A autenticação com a API Key configurada anteriormente (através de `genai.configure`) é necessária para acessar o modelo.\n",
        "* Você pode criar vários modelos com diferentes configurações de geração e segurança utilizando a mesma classe `GenerativeModel`.\n"
      ],
      "metadata": {
        "id": "W6kFxg5euFxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name= \"gemini-1.0-pro\",\n",
        "                              generation_config = generation_config,\n",
        "                              safety_settings = safety_settings)"
      ],
      "metadata": {
        "id": "qs6zwgUWqFbJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geração e Armazenamento de Feedback com Google Generative AI\n",
        "\n",
        "O código a seguir demonstra como gerar e armazenar feedback de prompts utilizando o Google Generative AI.\n",
        "\n",
        "O código cria arquivos de texto individuais para cada prompt na pasta feedback.\n",
        "\n",
        "Você pode modificar o formato do nome do arquivo ou a estrutura de armazenamento do feedback de acordo com suas necessidades.\n",
        "\n"
      ],
      "metadata": {
        "id": "fVW3WoNRuoqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Crie a pasta feedback se ela não existir\n",
        "if not os.path.exists('feedback'):\n",
        "    os.makedirs('feedback')\n",
        "\n",
        "# Dicionário com as strings de feedback\n",
        "feedback = {}\n",
        "\n",
        "for prompt in prompts_preparados:\n",
        "  response = model.generate_content(prompts_preparados[prompt])\n",
        "  feedback[prompt] = response.text\n",
        "\n",
        "# Percorra o dicionário\n",
        "for key, value in feedback.items():\n",
        "    # Crie um nome de arquivo usando a chave\n",
        "    filename = f'feedback/{key}.txt'\n",
        "\n",
        "    # Abra o arquivo em modo de escrita\n",
        "    with open(filename, 'w') as f:\n",
        "        # Escreva o feedback no arquivo\n",
        "        f.write(value)"
      ],
      "metadata": {
        "id": "kKsgS5CnxQ20"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lq0AKkqGu7x7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ideia de aprimoramento deste projeto\n",
        "\n",
        "Aprimorar este Script Python para analisar códigos Python coletados através de um formulário Google, comparando o código Python do aluno com um código gabarito de cada questão localizado em uma planilha Google. As respostas e orientações obtidas com a IA devem são armazenadas em uma planilha."
      ],
      "metadata": {
        "id": "UoQ6IQyLvICD"
      }
    }
  ]
}