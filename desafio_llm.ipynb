{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMouA30wT+0C25jHWqSnM6Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/costajr2019/Desafio_LLM/blob/main/desafio_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Desafio da Imersão IA\n",
        "\n",
        "[Imersão Inteligência Artificial 2ª - Desafio da Aula 04](https://cursos.alura.com.br/imersoes/aulas/aula-4-criando-seu-proprio-chatbot-com-a-gemini-api-no-google-colab-c131)\n",
        "\n",
        "##Objetivo\n",
        "\n",
        "Script Python que usa o LLM da Google para analisar códigos Python (postados por alunos) localizados em um pasta chamada \"respostas\", separados em arquivos, comparando o código Python do aluno com um código gabarito localizado em um arquivo gabarito.txt. As respostas e orientações obtidas com a IA devem são armazenadas nos respectivos arquivos em uma pasta denominada \"feedback\" como comentários nos respectivos arquivos dos alunos.\n",
        "\n",
        "##Dados\n",
        "\n",
        "| Arquivo | Conteúdo | Local de Armazenamento |\n",
        "| ---| --- | --- |\n",
        "| gabarito.txt | Script que produz a solução para o problema proposto.| Pasta Raíz |\n",
        "| prompt.txt | Prompt que descreve o conteúdo e a forma que o LLM deve apresentar sua análise. | Pasta Raíz\n",
        "| resposta_alunoN.txt | Script do N-ésimo aluno a ser avaliado pelo LLM | Pasta \"respostas\"\n",
        "\n",
        "##Saída\n",
        "| Arquivo | Conteúdo | Local de Armazenamento |\n",
        "|---|---| --- |\n",
        "| feedback_resposta_alunoN.txt | Feedback do LLM sobre o Script do N-ésimo aluno | Pasta \"feedback\"\n",
        "\n",
        "##Metodologia\n",
        "1. Para cada aluno, concatenar os conteúdos dos arquivos \"prompt.txt\", \"gabarito.txt\", e \"resposta_alunoN.txt\" para formar uma string contendo o prompt completo.\n",
        "2. Obter da LLM a avaliação do script Python de cada aluno a partir do respectivo prompt completo.\n",
        "3. Gravar as avaliações em arquivos separados na pasta \"feedback\"\n"
      ],
      "metadata": {
        "id": "YormlGbAHwWM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BrcPStNBHsUz"
      },
      "outputs": [],
      "source": [
        "def concatenar_strings(conteudo_prompt, conteudo_resposta, conteudo_gabarito):\n",
        "  \"\"\"\n",
        "  Função para concatenar o conteúdo de três strings em uma única string.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Cria a string separadora\n",
        "  separador = \"-\" * 50 + \"\\n\"\n",
        "\n",
        "  # Concatena os conteúdos dos arquivos\n",
        "  texto_concatenado = (\n",
        "      conteudo_prompt\n",
        "      + 2 * \"\\n\"\n",
        "      + \"**RESPOSTA DO ALUNO**\"\n",
        "      + \"\\n\"\n",
        "      + separador\n",
        "      + conteudo_resposta\n",
        "      + \"\\n\"\n",
        "      + \"\\n\"\n",
        "      + \"**GABARITO**\"\n",
        "      + \"\\n\"\n",
        "      + separador\n",
        "      + conteudo_gabarito\n",
        "  )\n",
        "\n",
        "  return texto_concatenado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def processar_respostas_alunos(pasta_respostas):\n",
        "  \"\"\"\n",
        "  Função para processar todas as respostas dos alunos em uma pasta.\n",
        "\n",
        "  Argumentos:\n",
        "    pasta_respostas: O caminho para a pasta que contém as respostas dos alunos.\n",
        "\n",
        "  Retorno:\n",
        "    Um dicionário onde as chaves são os nomes dos arquivos de resposta e os valores são as strings concatenadas contendo as respostas, prompts e gabaritos.\n",
        "  \"\"\"\n",
        "\n",
        "  # Carregar o conteúdo de prompt.txt, resposta_aluno.txt e gabarito.txt\n",
        "  with open(\"prompt.txt\") as prompt_file:\n",
        "    prompt = prompt_file.read()\n",
        "\n",
        "  with open(\"gabarito.txt\") as gabarito_file:\n",
        "    gabarito = gabarito_file.read()\n",
        "\n",
        "  respostas_processadas = {}\n",
        "\n",
        "  for arquivo in os.listdir(pasta_respostas):\n",
        "    if arquivo.endswith(\".txt\"):\n",
        "      nome_arquivo, extensao = os.path.splitext(arquivo)\n",
        "\n",
        "      with open(os.path.join(pasta_respostas, arquivo), 'r') as resposta_aluno_file:\n",
        "        resposta_aluno = resposta_aluno_file.read()\n",
        "\n",
        "      # Concatenar os conteúdos usando a função concatenar_arquivos\n",
        "      texto_concatenado = concatenar_strings(prompt, resposta_aluno, gabarito)\n",
        "\n",
        "      # Armazenar o texto concatenado no dicionário com o nome do arquivo como chave\n",
        "      respostas_processadas[nome_arquivo] = texto_concatenado\n",
        "\n",
        "  return respostas_processadas\n"
      ],
      "metadata": {
        "id": "vjV1dvZfmNh0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso\n",
        "pasta_respostas = \"respostas\"\n",
        "\n",
        "prompts_preparados = processar_respostas_alunos(pasta_respostas)\n",
        "\n",
        "# # Fazer algo com as respostas processadas, como imprimi-las ou salvá-las em um arquivo\n",
        "# for nome_arquivo, texto_concatenado in prompts_preparados.items():\n",
        "#   print(f\"## Resposta para {nome_arquivo}\")\n",
        "#   print(texto_concatenado)"
      ],
      "metadata": {
        "id": "bcfNJQBsmUpV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts_preparados:\n",
        "  print(prompts_preparados[prompt])"
      ],
      "metadata": {
        "id": "qmJ3ZevDw76P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Escrever o feedback de cada resposta da IA no correspondente arquivo na pasta feedback."
      ],
      "metadata": {
        "id": "X4x1rit_pIaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "JeeWPmXZpkuY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('SECRET_KEY')\n",
        "genai.configure(api_key = api_key)"
      ],
      "metadata": {
        "id": "VzP8aLPzpGsL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\" : 1,\n",
        "    \"temperature\" : 0.9, # Nível de criatividade\n",
        "    #\"top_p\" : 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "jJdvKF5ap5Yj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\" : \"BLOCK_NONE\",\n",
        "    \"HATE\" : \"BLOCK_NONE\",\n",
        "    \"SEXUAL\" : \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\" : \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "mq1s0y2fp8M9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name= \"gemini-1.0-pro\",\n",
        "                              generation_config = generation_config,\n",
        "                              safety_settings = safety_settings)"
      ],
      "metadata": {
        "id": "qs6zwgUWqFbJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Crie a pasta feedback se ela não existir\n",
        "if not os.path.exists('feedback'):\n",
        "    os.makedirs('feedback')\n",
        "\n",
        "# Dicionário com as strings de feedback\n",
        "feedback = {}\n",
        "\n",
        "for prompt in prompts_preparados:\n",
        "  response = model.generate_content(prompts_preparados[prompt])\n",
        "  feedback[prompt] = response.text\n",
        "\n",
        "# Percorra o dicionário\n",
        "for key, value in feedback.items():\n",
        "    # Crie um nome de arquivo usando a chave\n",
        "    filename = f'feedback/{key}.txt'\n",
        "\n",
        "    # Abra o arquivo em modo de escrita\n",
        "    with open(filename, 'w') as f:\n",
        "        # Escreva o feedback no arquivo\n",
        "        f.write(value)"
      ],
      "metadata": {
        "id": "kKsgS5CnxQ20"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}